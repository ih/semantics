* next
write test for semantic-match
** DONE write test for select-action
write basic test for generate-plan
** DONE figure out how to reload a module in geiser mode (or repl)
sent an email to the geiser email list

** DONE test for process-input is to see if eval of first thing in memory is the input
write test for process-input of agent.scm
how would you do this without objects?
** develop test cases for interaction-loop
may require redesigning how interaction loop works e.g. by passing in a list of inputs
*** DONE create a simple agent that chooses an arbitrary action
*** DONE write a test case for process-inputs to make sure the loop is correct
**** TODO2 make switching agents in/out easier by having it be an argument to process-inputs
** implement generate-plan
write reverse evaluation
keep in mind for classification this should probably create one step plans i.e. programs with a single operation
* past
currently trying to get (evaluate 'cons) to work
** implement lookup-variable-value
*** DONE implement scan
*** DONE write test for scan
more generally make an environment for testing eval
* outline
** interpreter
*** features
**** applying semantics
output of functions can be partially determined based on the semantics
**** learning semantics
common sequences of operations are abstracted and added as functions in the language
*** applications
**** agent architecture
**** binary string classification
classify binary strings, architect as a sequential decision problem?
***** environment
****** present input
****** take in action
****** give feedback

***** agent architecture
****** process input
****** select action
conditional based on inputs for selecting a different action?

what does learning the semantics for an individual action in the single decision problem mean?

creating a map from input output

so what goes through the interpreter should be the decision and the input, not just the decision, the decision is the thing that should be evaluated, the input is part of the environment(?)

do a search over actions to maximize goal using semantics
******* TODO generate plan
implement as reversing a computation
******** match desired output to post-conditions of actions
start with the highest level actions first
perform unification
******** create a new possible plan for each match
******** set precondition to be new goal and extend possible plans
repeat until current input is reached as a precondition****** learn from feedback
**** warehouse world
the domain presented in angelic semantics papers by russell's group
***** reimplement warehouse world
***** apply abstraction code to learning high level actions
* overview
** motivation
*** high level/abstract actions beneficial in planning
smaller space of plans
*** planning over sets of states, refining individual actions
*** learning sequences of actions is like programming/algorithm design
*** function definition powerful tool in programming
function as an abstraction of commonly repeated sequence of actions

*** learning semantics for high level actions
**** actions as state transitions
**** high level actions as state-set transitions
is this true?
**** in angelic semantics DNF formula used to describe sets for pre and post conditions of an action
allow for richer abstraction/language, bigger state sets

shape as an example of the importance of higher order abstractions, flower example (brown base, long green stem, alternating red/yellow colored flowers)

** approach
*** planning as reverse interpretation
The idea is to use the semantics developed while running the interpreter forward to create programs when we only have the input and output by matching the output to post-conditions of operators then seeing if the pre-condition of that operator matches the input

the basic objects are potential programs (i.e. lists of operators)
